# Welcome to MetaIoT Lab!

## üôã‚Äç‚ôÄÔ∏è Introduction

Hello! This is the GitHub space for the **Mobile, Sensing, Automative & Internet of Things Lab (MetaIoT)**. Our group is led by **Prof. [Wei Wang](https://metaiot.group/weiwang.html)** (WHU).

We create the **next generation of intelligent unmanned systems** for sensing and perception. Our research bridges the gap between hardware and intelligence, with applications in **autonomous systems, AIoT, and Embodied AI**.

## üî¨ Research Focus

Our research focuses on **wireless sensing, ubiquitous computing, and mobile intelligence**. We are particularly interested in:

* **Spatial Perception and Intelligence for Embodied AI**
  Integrating perception, cognition, and action for autonomous agents in complex environments. Millimeter-wave radar with Spatial-Doppler representation empowers spatial perception, enabling reliable sensing and motion understanding.

* **mmWave/Multi-modal 3D Perception and SLAM**
  Utilizing mmWave Radar perception and multi-modal SLAM/navigation for self-driving vehicles. We provide solutions for low-power, self-monitored, ultra-accurate radar systems in automotive and industrial applications.

* **AIoT & Ultra-low-power Networks**
  Designing AIoT hardware and embedded systems, specifically focusing on ultra-low-power IoT networks powered by ambient energy (Backscatter communication) for industry and healthcare.

## üöÄ Selected Works & Highlights

We strive to push the boundaries of sensing and perception. Some of our recent impactful works include:

* **[AAAI'26 Oral] RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent Diffusion**
  A novel latent diffusion framework that bridges the gap between sparse radar spectra and dense 3D perception. It integrates a scene-level frustum-based LiDAR autoencoder and order-invariant latent representations to generate high-fidelity point clouds from raw radar data.

* **[ICCV'25] S¬≥E: Self-Supervised State Estimation for Radar-Inertial System**
  The first self-supervised state estimator fusing radar spectra and inertial data. It introduces a novel rotation-based cross-fusion technique to enhance spatial structure and exploits Doppler velocities to compensate for IMU drift, achieving robust localization without ground truth.

* **[IJCAI'25] SDDiff: Boosting Radar Perception via Spatial-Doppler Diffusion**
  A Spatial-Doppler Diffusion model designed to simultaneously achieve dense point cloud extraction (PCE) and accurate ego velocity estimation (EVE). It unlocks the reciprocal synergy between spatial occupancy and Doppler velocity features to refine ghost-prone representations.

## üåà Collaboration & Guidelines

We actively contribute to the research community through high-quality publications and open-source projects.

* **Research Collaboration:** We are open to academic and industrial collaborations in wireless sensing, autonomous driving, and AIoT.
* **Prospective Students:** We are always looking for self-motivated students interested in mobile computing and sensing. Please check our faculty homepages for recruitment information.
* **Using Our Code:** You are welcome to explore and use the code in our repositories. Please ensure you cite the corresponding publications appropriately.
* **Issues & Contributions:** If you encounter issues with our open-source tools, please file an issue in the respective repository.

## üë©‚Äçüíª Useful Resources

* **Lab Website:** [https://metaiot.group/](https://metaiot.group/)
* **Prof. Wei Wang's Homepage:** [https://metaiot.group/weiwang.html](https://metaiot.group/weiwang.html)
